---
layout: page
title: Potential Readings
desc: "Potential Readings of Deep Learning We Plan to Finish in 2017-Fall"
---

<hr>

<p><a name="topPage"></a></p>

<hr>

<font face="Arial,Helvetica">
<ul>
<li><a href="#Foud">Topic I: Foundations </a> </li>
<li><a href="#Stru">Topic II: DNN with Varying Structures</a> </li>
<li><a href="#App">Topic III: Reliable and Benchmarking and Applications </a> </li>
<li><a href="#Opt">Topic IV: Optimization </a> </li>
<li><a href="#Gen">Topic V: Generative  </a> </li>
<li><a href="#RL">Topic VI: Reinforcement </a> </li>
</ul>
</font>





<!--

<hr>

<p><a name="Foud"></a></p>


## Foundations
0. [DeepLearningSummerSchool17](https://mila.umontreal.ca/en/cours/deep-learning-summer-school-2017/)
1. Andrew Ng - Nuts and Bolts of Applying Deep Learning : https://www.youtube.com/watch?v=F1ka6a13S9I  :
2. Ganguli - Theoretical Neuroscience and Deep Learning.pdf DLSS17 https://drive.google.com/file/d/0B6NHiPcsmak1dkZMbzc2YWRuaGM/view
3. Richards - Deep_Learning_in_the_Brain.pd https://drive.google.com/file/d/0B2A1tnmq5zQdcFNkWU1vdDJiT00/view and
https://drive.google.com/file/d/0B2A1tnmq5zQdQWU0Skd6TVVQYUE/view?usp=drive_web
4. Sharp Minima Can Generalize For Deep Nets, Laurent Dinh (Univ. Montreal), Razvan Pascanu, Samy Bengio (Google Brain), Yoshua Bengio (Univ. Montreal)
5. Automated Curriculum Learning for Neural Networks, Alex Graves, Marc G. Bellemare, Jacob Menick, Koray Kavukcuoglu, Remi Munos
6. Learning to learn without gradient descent by gradient descent, Yutian Chen, Matthew Hoffman, Sergio Gomez, Misha Denil, Timothy Lillicrap, Matthew Botvinick , Nando de Freitas
7. Cognitive Psychology for Deep Neural Networks: A Shape Bias Case Study, Samuel Ritter*, David Barrett*, Adam Santoro, Matt Botvinick
8. Geometry of Neural Network Loss Surfaces via Random Matrix Theory, Jeffrey Pennington, Yasaman Bahri
9. On the Expressive Power of Deep Neural Networks, Maithra Raghu, Ben Poole, Surya Ganguli, Jon Kleinberg, Jascha Sohl-Dickstein
10. Neuroscience-Inspired Artificial Intelligence, http://www.cell.com/neuron/fulltext/S0896-6273(17)30509-3
11. Understanding deep learning requires rethinking generalization, ICLR17
12. On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima, ICLR17
13. Normalizing the Normalizers: Comparing and Extending Network Normalization Schemes, ICLR17
14. Capacity and Trainability in Recurrent Neural Networks, ICLR17
15. Zoneout: Regularizing RNNs by Randomly Preserving Hidden Activations, ICLR17
16. Frustratingly Short Attention Spans in Neural Language Modeling, ICLR17
17. Topology and Geometry of Half-Rectified Network Optimization, ICLR17
18. Central Moment Discrepancy (CMD) for Domain-Invariant Representation Learning, ICLR17
19. Adversarial Feature Learning, ICLR17
20. Do Deep Convolutional Nets Really Need to be Deep and Convolutional?, ICLR17
21. Why Deep Neural Networks for Function Approximation?, ICLR17

<hr>

<p><a name="Stru"></a></p>


## DNN with Varying Structures
1. SCAN: Learning Abstract Hierarchical Compositional Visual Concepts, https://arxiv.org/pdf/1707.03389.pdf
2. Krueger - Bayesian Hypernetworks.pdf https://drive.google.com/file/d/0B6NHiPcsmak1RUlucW1RN29oS3M/view?usp=drive_web
3. Leblond and Alayrac - SeaRNN.pdf https://drive.google.com/file/d/0B6NHiPcsmak1SDVEaWc0OWtaV0k/view?usp=drive_web
4. Sharir - Overlapping Architectures.pdf https://drive.google.com/file/d/0B6NHiPcsmak1ZzVkci1EdVN2YkU/view?usp=drive_web
5. Ullrich - Bayesian Compression.pd https://drive.google.com/file/d/0B6NHiPcsmak1WlRUeHFpSW5OZGc/view?usp=drive_web
6. Understanding Synthetic Gradients and Decoupled Neural Interfaces, Wojtek Czarnecki, Grzegorz Świrszcz, Max Jaderberg, Simon Osindero, Oriol Vinyals, Koray Kavukcuoglu
7. Video Pixel Networks, Nal Kalchbrenner, Aaron van den Oord, Karen Simonyan, Ivo Danihelka, Oriol Vinyals, Alex Graves, Koray Kavukcuoglu
8. AdaNet: Adaptive Structural Learning of Artificial Neural Networks, Corinna Cortes, Xavi Gonzalvo, Vitaly Kuznetsov, Mehryar Mohri, Scott Yang
9. Learning to Generate Long-term Future via Hierarchical Prediction, Ruben Villegas, Jimei Yang, Yuliang Zou, Sungryull Sohn, Xunyu Lin, Honglak Lee
10. Zero-Shot Task Generalization with Multi-Task Deep Reinforcement Learning, Junhyuk Oh, Satinder Singh, Honglak Lee, Pushmeet Kohli
11. Latent LSTM Allocation: Joint Clustering and Non-Linear Dynamic Modeling of Sequence Data,  Manzil Zaheer, Amr Ahmed, Alex Smola
12. Large-Scale Evolution of Image Classifiers, Esteban Real, Sherry Moore, Andrew Selle, Saurabh Saxena, Yutaka Leon Suematsu, Jie Tan, Quoc Le, Alexey Kurakin
13. Sequence Modeling via Segmentations, Chong Wang (Microsoft Research) · Yining Wang (CMU) · Po-Sen Huang (Microsoft Research) · Abdelrahman Mohammad (Microsoft) · Dengyong Zhou (Microsoft Research) · Li Deng (Citadel)
14. ProtoNN: Compressed and Accurate kNN for Resource-scarce Devices
15. Adaptive Neural Networks for Fast Test-Time Prediction
16. Making Neural Programming Architectures Generalize via Recursion, ICLR17
17. Optimization as a Model for Few-Shot Learning, ICLR17
18. Learning End-to-End Goal-Oriented Dialog, ICLR17
19. Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer, ICLR17
20. Nonparametric Neural Networks, ICLR17
21. An Information-Theoretic Framework for Fast and Robust Unsupervised Learning via Neural Population Infomax, ICLR17
22. Improving Neural Language Models with a Continuous Cache, ICLR17
23. Variational Recurrent Adversarial Deep Domain Adaptation, ICLR17
24. Soft Weight-Sharing for Neural Network Compression, ICLR17
25. Tracking the World State with Recurrent Entity Networks, (Lecun),  ICLR17
26. Deep Biaffine Attention for Neural Dependency Parsing, ICLR17
27. Learning to Remember Rare Events, ICLR17
28. Transfer Learning for Sequence Tagging with Hierarchical Recurrent Networks, ICLR17
29. Deep Learning with Dynamic Computation Graphs, ICLR17
30. Query-Reduction Networks for Question Answering, ICLR17
31. Bidirectional Attention Flow for Machine Comprehension, ICLR17
32. Dynamic Coattention Networks For Question Answering, ICLR17
33. Structured Attention Networks, ICLR17
34. Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer, (Dean), ICLR17
35. Attend, Adapt and Transfer: Attentive Deep Architecture for Adaptive Transfer from multiple sources in the same domain, ICLR17
36. Mollifying Networks, Bengio, ICLR17
37. Automatic Rule Extraction from Long Short Term Memory Networks, ICLR17
38. Loss-aware Binarization of Deep Networks, ICLR17
39. Deep Multi-task Representation Learning: A Tensor Factorisation Approach, ICLR17
40. Towards Deep Interpretability (MUS-ROVER II): Learning Hierarchical Representations of Tonal Music, ICLR17
41. Reasoning with Memory Augmented Neural Networks for Language Comprehension, ICLR17
42. Semi-Supervised Classification with Graph Convolutional Networks, ICLR17
43. Hierarchical Multiscale Recurrent Neural Networks, ICLR17

<hr>

<p><a name="App"></a></p>
## Reliable and Benchmarking and Applications
1. Ganguli - Theoretical Neuroscience and Deep Learning DLSS16 http://videolectures.net/deeplearning2016_ganguli_theoretical_neuroscience/
2. Dhruv - Visual Dialog - RLSS 2017 https://drive.google.com/file/d/0BzUSSMdMszk6RndSbkEzcnRFMGs/view and
https://drive.google.com/file/d/0BzUSSMdMszk6cDVBMlRqLUs3TFk/view
3. Input Switched Affine Networks: An RNN Architecture Designed for Interpretability, Jakob Foerster, Justin Gilmer, Jan Chorowski, Jascha Sohl-Dickstein, David Sussillo
4. Axiomatic Attribution for Deep Networks, Ankur Taly, Qiqi Yan,,Mukund Sundararajan
5. Differentiable Programs with Neural Libraries, Alex L Gaunt, Marc Brockschmidt, Nate Kushman, Daniel Tarlow
6. Neural Optimizer Search with Reinforcement Learning, Irwan Bello, Barret Zoph, Vijay Vasudevan, Quoc Le
7. Measuring Sample Quality with Kernels, Jackson Gorham (STANFORD) · Lester Mackey (Microsoft Research)
8. Learning Continuous Semantic Representations of Symbolic Expressions
9. Recovery Guarantees for One-hidden-layer Neural Networks
10. On the State of the Art of Evaluation in Neural Language Models, https://arxiv.org/abs/1707.05589
11. End-to-end Optimized Image Compression, ICLR17
12. Multi-Agent Cooperation and the Emergence of (Natural) Language, ICLR17
13. Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data, ICLR17
14. Deep Learning with Differential Privacy,
15. Privacy-Preserving Deep Learning, CCS15
16. Learning to Query, Reason, and Answer Questions On Ambiguous Texts, ICLR17
17. Generative Models and Model Criticism via Optimized Maximum Mean Discrepancy, ICLR17
18. Data Noising as Smoothing in Neural Network Language Models (Ng), ICLR17
19. A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks, ICLR17
20. Visualizing Deep Neural Network Decisions: Prediction Difference Analysis, ICLR17
21. On Detecting Adversarial Perturbations, ICLR17
22. Delving into Transferable Adversarial Examples and Black-box Attacks, ICLR17

<hr>

<p><a name="Opt"></a></p>

## Optimization
1. Johnson - Automatic Differentiation.p https://drive.google.com/file/d/0B6NHiPcsmak1ckYxR2hmRGdzdFk/view
2. Osborne - Probabilistic numerics for deep learning - DLSS 2017.pdf https://drive.google.com/file/d/0B2A1tnmq5zQdWHBYOFctNi1KdVU/view
3. Learned Optimizers that Scale and Generalize, Olga Wichrowska, Niru Maheswaranathan, Matthew Hoffman, Sergio Gomez, Misha Denil, Nando de Freitas, Jascha Sohl-Dickstein
4. Learning to learn by gradient descent by gradient descent
5. Asynchronous Stochastic Gradient Descent with Delay Compensation,
6. How to Escape Saddle Points Efficiently, Chi Jin (UC Berkeley) · Rong Ge (Duke University) · Praneeth Netrapalli (Microsoft Research) · Sham M. Kakade (University of Washington) · Michael Jordan (UC Berkeley)
7. Natasha: Faster Non-Convex Stochastic Optimization Via Strongly Non-Convex Parameter
8. Batched High-dimensional Bayesian Optimization via Structural Kernel Learning
9. Towards Principled Methods for Training Generative Adversarial Networks, ICLR17
10. Optimization as a Model for Few-Shot Learning, ICLR17
11. Amortised MAP Inference for Image Super-resolution, ICLR17
12. Neural Architecture Search with Reinforcement Learning, ICLR17
13. Distributed Second-Order Optimization using Kronecker-Factored Approximations, ICLR17
14. Mode Regularized Generative Adversarial Networks, ICLR17
15. Highway and Residual Networks learn Unrolled Iterative Estimation, ICLR17
16. Snapshot Ensembles: Train 1, Get M for Free, ICLR17
17. Learning to Optimize, ICLR17
18. Recurrent Batch Normalization, ICLR17
19. Adversarially Learned Inference, ICLR17
20. Reasoning with Memory Augmented Neural Networks for Language Comprehension, ICLR17

<hr>

<p><a name="Gen"></a></p>

## Generative
0. Bengio - Recurrent Neural Networks - DLSS 2017.pdf: https://drive.google.com/file/d/0ByUKRdiCDK7-LXZkM3hVSzFGTkE/view
1. Goodfellow - Generative Models I - DLSS 2017 https://drive.google.com/file/d/0ByUKRdiCDK7-bTgxTGoxYjQ4NW8/view
2. Courville - Generative Models II - DLSS 2017. https://drive.google.com/file/d/0B_wzP_JlVFcKQ21udGpTSkh0aVk/view
3. Makhzani and Frey - PixelGAN Autoencoders.pdf https://drive.google.com/file/d/0B6NHiPcsmak1SFdRN2lmS3FnekE/view
4. Welling - Graphical Models and Deep Learning.pd  https://drive.google.com/file/d/0B6NHiPcsmak1NHJHdzEySzNNQ0U/view
5. Parallel Multiscale Autoregressive Density Estimation, Scott Reed, Aäron van den Oord, Nal Kalchbrenner, Ziyu Wang, Dan Belov, Nando de Freitas
6. Count-Based Exploration with Neural Density Models, Georg Ostrovski, Marc Bellemare, Aaron van den Oord, Remi Munos
7. Learning Deep Latent Gaussian Models with Markov Chain Monte Carlo, Maithra Raghu, Ben Poole, Surya Ganguli, Jon Kleinberg, Jascha Sohl-Dickstein
8. Johnson - Graphical Models and Deep Learning https://drive.google.com/file/d/0B6NHiPcsmak1RmZ3bmtFWUd5bjA/view?usp=drive_web
9. Variational Boosting: Iteratively Refining Posterior Approximations, Andrew Miller, Nicholas J Foti, Ryan Adams
10. Stochastic Generative Hashing, Bo Dai, Ruiqi Guo, Sanjiv Kumar, Niao He, Le Song
11. Robust Structured Estimation with Single-Index Models, ICML17
12. Learning to Act by Predicting the Future, ICLR17
13. Improving Generative Adversarial Networks with Denoising Feature Matching, ICLR17
14. Boosted Generative Models, ICLR17
15. The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables, ICLR17

<hr>

<p><a name="RL"></a></p>

## Reinforcement
0.  Hasselt - Deep Reinforcement Learning - RLSS 2017.pdf https://drive.google.com/file/d/0BzUSSMdMszk6UE5TbWdZekFXSE0/view?usp=drive_web
1. Pineau - RL Basic Concepts - RLSS 2017.pdf https://drive.google.com/file/d/0BzUSSMdMszk6bjl3eU5CVmU0cWs/view
http://videolectures.net/deeplearning2016_pineau_reinforcement_learning/
and http://videolectures.net/deeplearning2016_pineau_advanced_topics/
2. Roux - RL in the Industry - RLSS 2017.pdf https://drive.google.com/file/d/0BzUSSMdMszk6bEprTUpCaHRrQ28/view
3. Singh - Steps Towards Continual Learning.pdf https://drive.google.com/file/d/0BzUSSMdMszk6YVhFUUNLZnZLSWs/view?usp=drive_web
4. Sutton - Temporal-Difference Learning- RLSS 2017.pd https://drive.google.com/file/d/0BzUSSMdMszk6VE9kMkY2SzQzSW8/view?usp=drive_web
5. Szepesvari - Theory of RL - RLSS 2017.pdf https://drive.google.com/file/d/0BzUSSMdMszk6U194Ym5jSnZQbGM/view?usp=drive_web
6. Thomas - Safe Reinforcement Learning - RLSS 2017.pdf https://drive.google.com/file/d/0BzUSSMdMszk6TDRMRGRaM0dBcHM/view?usp=drive_web
7. Minimax Regret Bounds for Reinforcement Learning, Mohammad Gheshlaghi Azar, Ian Osband, Remi Munos
8. Why is Posterior Sampling Better than Optimism for Reinforcement Learning? Ian Osband, Benjamin Van Roy
9. DARLA: Improving Zero-Shot Transfer in Reinforcement Learning, Irina Higgins*, Arka Pal*, Andrei Rusu, Loic Matthey, Chris Burgess, Alexander Pritzel, Matt Botvinick, Charles Blundell, Alexander Lerchner
10. A Distributional Perspective on Reinforcement Learning, Marc G. Bellemare*, Will Dabney*, Remi Munos
11. A Laplacian Framework for Option Discovery in Reinforcement Learning, Marlos Machado (Univ. Alberta), Marc G. Bellemare, Michael Bowling
12. The Predictron: End-to-End Learning and Planning, David Silver, Hado van Hasselt, Matteo Hessel, Tom Schaul, Arthur Guez, Tim Harley, Gabriel Dulac-Arnold, David Reichert, Neil Rabinowitz, Andre Barreto, Thomas Degris
13. FeUdal Networks for Hierarchical Reinforcement Learning, Sasha Vezhnevets, Simon Osindero, Tom Schaul, Nicolas Hees, Max Jaderberg, David Silver, Koray Kavukcuoglu
14.  Neural Episodic Control, Alex Pritzel, Benigno Uria, Sriram Srinivasan, Adria Puigdomenech, Oriol Vinyals, Demis Hassabis, Daan Wierstra, Charles Blundell
15. Robust Adversarial Reinforcement Learning, Lerrel Pinto, James Davidson, Rahul Sukthankar, Abhinav Gupta
16. Deep Value Networks Learn to Evaluate and Iteratively Refine Structured Outputs, Michael Gygli, Mohammad Norouzi, Anelia Angelova
17. Distral: Robust Multitask Reinforcement Learning, https://arxiv.org/pdf/1707.04175.pdf
18. Reinforcement Learning with Unsupervised Auxiliary Tasks, ICLR17
19. Q-Prop: Sample-Efficient Policy Gradient with An Off-Policy Critic, ICLR17


<hr>

## More:
1. [ICLR 2017 Papers](https://openreview.net/group?id=ICLR.cc/2017/conference)
2. [ICML 2017 Papers](https://2017.icml.cc/Conferences/2017/Schedule?type=Poster)
3. [NIPS 2017 papers](https://nips.cc/Conferences/2016/AcceptedPapers)
4. [Yann Lecun](http://yann.lecun.com/exdb/publis/index.html)
5. [Y. Bengio](https://scholar.google.com/citations?user=kukA0LcAAAAJ)
6. [G. Hinton](https://scholar.google.com/citations?user=JicYPdAAAAAJ&hl=en)
7. [Juergen Schmidhuber](https://scholar.google.com/citations?user=gLnCTgIAAAAJ&hl=en&oi=sra)

<hr>


<div style="position: fixed; bottom: 76px; right:10px; width: 118px; height: 236px; background-color: #FFCF79;">
<a style="position: fixed; bottom:130px; right:10px;" href="#Foud">I: Foundations</a>
<a style="position: fixed; bottom:155px; right:10px;" href="#Stru">II: Structures</a>
<a style="position: fixed; bottom:180px; right:10px;" href="#App">III: Apps</a>
<a style="position: fixed; bottom:205px; right:10px;" href="#Opt">IV: Optimization</a>
<a style="position: fixed; bottom:230px; right:10px;" href="#Gen">V: Generative</a>
<a style="position: fixed; bottom:255px; right:10px;" href="#RL">VI: RL</a>
<a style="position: fixed; bottom:80px; right:10px;" href="#topPage" title="Back to Top">BackTop</a>
</div>

### DeepMind papers
### Facebook Fair/Lecun Papers
### Bengio Papers

### NIPS 2016 Papers
###
###

-->
