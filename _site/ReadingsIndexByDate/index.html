<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Readings ByDate &middot; Deep Learning 2Read
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/deep2Read/public/css/poole.css">
  <link rel="stylesheet" href="/deep2Read/public/css/syntax.css">
  <link rel="stylesheet" href="/deep2Read/public/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Rubik" >

  <!-- Icons -->
  <link rel="shortcut icon" href="/deep2Read/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/deep2Read/atom.xml">

</head>


  <body class="theme-base-06">

  	<!--<body class="theme-base-08">
    <body class="theme-gradient">
    <body class="theme-base-09">
	<body class="layout-reverse">-0-->

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/deep2Read/">
          Deep Learning 2Read
        </a>
      </h1> <br><br>
      <p class="lead">A List of Deep Learning Papers We Read:</p>
    </div>

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item" href="/deep2Read/">Home</a>

      

      
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="/deep2Read//About/">Course Information</a>
          
        
      
        
          
            <a class="sidebar-nav-item" href="/deep2Read//Basic2LearnDeep/">Basic Readings</a>
          
        
      
        
          
            <a class="sidebar-nav-item" href="/deep2Read//Potential2Read/">Potential Readings</a>
          
        
      
        
          
            <a class="sidebar-nav-item active" href="/deep2Read//ReadingsIndexByDate/">Readings ByDate</a>
          
        
      
        
          
            <a class="sidebar-nav-item" href="/deep2Read//ReadingsIndexByTags/">Readings ByTag</a>
          
        
      
        
      
        
          
        
      
      <br>
      <a class="sidebar-nav-item" href="https://github.com/QData/deep2Read" target="_blank" >Site GitHub</a>
      <a class="sidebar-nav-item" href="http://www.cs.virginia.edu/yanjun/" target="_blank" >UVA Qdata Lab</a>
      <p>&copy;  <a href="https://twitter.com/Qdatalab" data-widget-id="459649185759764482">Tweets by @Qdatalab</a></p>

    </nav>

  </div>
</div>


    <div class="content container">
      <div class="page">
  <h1 class="page-title">Our Reviews of Deep Learning Readings by Date-Read</h1>
  <div class="posts">

  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/12/05/">
        RL V - RL with varying Applications
      </a>
    </h1>

    <span class="post-date">- 05 Dec 2017</span>

    <ul>
  <li>Deep Value Networks Learn to Evaluate and Iteratively Refine
Structured Outputs, Michael Gygli, Mohammad Norouzi, Anelia Angelova</li>
  <li>Distral: Robust Multitask Reinforcement Learning,
https://arxiv.org/pdf/1707.04175.pdf</li>
  <li>Deeply AggreVaTeD: Differentiable Imitation Learning for Sequential
Prediction, Wen Sun, Arun Venkatraman, Geoffrey J. Gordon, Byron Boots,
J. Andrew Bagnell ; PMLR 70:3309-3318</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/11/30/">
        RL IV - RL with varying structures
      </a>
    </h1>

    <span class="post-date">- 30 Nov 2017</span>

    <ul>
  <li>The Predictron: End-to-End Learning and Planning, David Silver, Hado
van Hasselt, Matteo Hessel, Tom Schaul, Arthur Guez, Tim Harley, Gabriel
Dulac-Arnold, David Reichert, Neil Rabinowitz, Andre Barreto, Thomas Degris</li>
  <li>FeUdal Networks for Hierarchical Reinforcement Learning, Sasha
Vezhnevets, Simon Osindero, Tom Schaul, Nicolas Hees, Max Jaderberg,
David Silver, Koray Kavukcuoglu</li>
  <li>Reinforcement Learning with Unsupervised Auxiliary Tasks, ICLR17</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/11/28/">
        RL III - Basic tutorial RLSS17 (2)
      </a>
    </h1>

    <span class="post-date">- 28 Nov 2017</span>

    <ul>
  <li>Sutton - Temporal-Difference Learning- RLSS 2017.pd
https://drive.google.com/file/d/0BzUSSMdMszk6VE9kMkY2SzQzSW8/view?usp=drive_web</li>
  <li>Szepesvari - Theory of RL - RLSS 2017.pdf
https://drive.google.com/file/d/0BzUSSMdMszk6U194Ym5jSnZQbGM/view?usp=drive_web</li>
  <li>Thomas - Safe Reinforcement Learning - RLSS 2017.pdf
https://drive.google.com/file/d/0BzUSSMdMszk6TDRMRGRaM0dBcHM/view?usp=drive_web</li>
  <li>Why is Posterior Sampling Better than Optimism for Reinforcement
Learning? Ian Osband, Benjamin Van Roy</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/11/21/">
        RL II - Basic tutorial RLSS17
      </a>
    </h1>

    <span class="post-date">- 21 Nov 2017</span>

    <ul>
  <li>Hasselt - Deep Reinforcement Learning - RLSS 2017.pdf
https://drive.google.com/file/d/0BzUSSMdMszk6UE5TbWdZekFXSE0/view?usp=drive_web</li>
  <li>Roux - RL in the Industry - RLSS 2017.pdf
https://drive.google.com/file/d/0BzUSSMdMszk6bEprTUpCaHRrQ28/view</li>
  <li>Singh - Steps Towards Continual Learning.pdf
https://drive.google.com/file/d/0BzUSSMdMszk6YVhFUUNLZnZLSWs/view?usp=drive_web</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/11/16/">
        Generative III -  GAN and More
      </a>
    </h1>

    <span class="post-date">- 16 Nov 2017</span>

    <ul>
  <li>
    <p>Generalization and Equilibrium in Generative Adversarial Nets (GANs),
ICML17</p>
  </li>
  <li>
    <p>Generative Models and Model Criticism via Optimized Maximum Mean
Discrepancy, ICLR17</p>
  </li>
  <li>
    <p>Improving Generative Adversarial Networks with Denoising Feature
Matching, ICLR17</p>
  </li>
  <li>Stochastic Generative Hashing, Bo Dai, Ruiqi Guo, Sanjiv Kumar, Niao
He, Le Song, ICML17</li>
  <li>Robust Structured Estimation with Single-Index Models, ICML17</li>
  <li>Learning Hierarchical Features from Deep Generative Models, Shengjia
Zhao, Jiaming Song, Stefano Ermon ; PMLR 70:4091-4099</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/11/14/">
        Generative II - Deep Generative Models
      </a>
    </h1>

    <span class="post-date">- 14 Nov 2017</span>

    <ul>
  <li>
    <p>Courville - Generative Models II - DLSS 2017.  https://drive.google.com/file/d/0B_wzP_JlVFcKQ21udGpTSkh0aVk/view</p>
  </li>
  <li>
    <p>Johnson - Graphical Models and Deep Learning https://drive.google.com/file/d/0B6NHiPcsmak1RmZ3bmtFWUd5bjA/view?usp=drive_web</p>
  </li>
  <li>
    <p>Attend, Infer, Repeat: Fast Scene Understanding with Generative
Models, NIPS16</p>
  </li>
  <li>Parallel Multiscale Autoregressive Density Estimation, Scott Reed,
AÃ¤ron van den Oord, Nal Kalchbrenner, Ziyu Wang, Dan Belov, Nando de Freitas</li>
  <li>Generative Models and Model Criticism via Optimized Maximum Mean
Discrepancy, ICLR17</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/11/09/">
        Optimization IV -   DNN for Optimization
      </a>
    </h1>

    <span class="post-date">- 09 Nov 2017</span>

    <ul>
  <li>Axiomatic Attribution for Deep Networks, Mukund Sundararajan, Ankur
Taly, Qiqi Yan ; PMLR 70:3319-3328</li>
  <li>End-to-End Differentiable Adversarial Imitation Learning, ICML17</li>
  <li>Neural Optimizer Search with Reinforcement Learning, ICML17</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/11/07/">
        Optimization III -   Optimization for DNN
      </a>
    </h1>

    <span class="post-date">- 07 Nov 2017</span>

    <ul>
  <li>Sharp Minima Can Generalize For Deep Nets, ICML17</li>
  <li>Forward and Reverse Gradient-Based Hyperparameter Optimization, ICML17</li>
  <li>Adaptive Neural Networks for Efficient Inference, ICML17</li>
  <li>Practical Gauss-Newton Optimisation for Deep Learning, ICML17</li>
  <li>
    <p>Professor Forcing: A New Algorithm for Training Recurrent Networks, NIPS16</p>
  </li>
  <li>Axiomatic Attribution for Deep Networks, Mukund Sundararajan, Ankur
Taly, Qiqi Yan ; PMLR 70:3319-3328</li>
  <li>End-to-End Differentiable Adversarial Imitation Learning, ICML17</li>
  <li>Neural Optimizer Search with Reinforcement Learning, ICML17</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/11/02/">
        Optimization II -  DNN for Optimization
      </a>
    </h1>

    <span class="post-date">- 02 Nov 2017</span>

    <ul>
  <li>Batched High-dimensional Bayesian Optimization via Structural Kernel
Learning</li>
  <li>Optimization as a Model for Few-Shot Learning, ICLR17</li>
  <li>Neural Architecture Search with Reinforcement Learning, ICLR17</li>
  <li>Automated Curriculum Learning for Neural Networks, ICML17</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/10/31/">
        Optimization I - Understanding DNN Optimization
      </a>
    </h1>

    <span class="post-date">- 31 Oct 2017</span>

    <ul>
  <li>
    <p>An overview of gradient optimization algorithms,
(https://arxiv.org/abs/1609.04747)</p>
  </li>
  <li>Johnson - Automatic Differentiation.p
https://drive.google.com/file/d/0B6NHiPcsmak1ckYxR2hmRGdzdFk/view</li>
  <li>Osborne - Probabilistic numerics for deep learning - DLSS 2017.pdf
https://drive.google.com/file/d/0B2A1tnmq5zQdWHBYOFctNi1KdVU/view</li>
  <li>How to Escape Saddle Points Efficiently, Chi Jin (UC Berkeley) Â· Rong
Ge (Duke University) Â· Praneeth Netrapalli (Microsoft Research) Â· Sham
M. Kakade (University of Washington) Â· Michael Jordan (UC Berkeley), ICML17</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/10/26/">
        Reliable Applications VI - Robustness
      </a>
    </h1>

    <span class="post-date">- 26 Oct 2017</span>

    <ul>
  <li>Robustness of classifiers: from adversarial to random noise, NIPS16</li>
  <li>Examples are not Enough, Learn to Criticize! Model Criticism for
Interpretable Machine Learning, NIPS16</li>
  <li>Blind Attacks on Machine Learners, Alex Beatson*, Princeton
University; Zhaoran Wang, Princeton University; Han Liu, NIPS16</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/10/24/">
        Reliable Applications V - Understanding and Composing DNNs
      </a>
    </h1>

    <span class="post-date">- 24 Oct 2017</span>

    <ul>
  <li>Toward Deeper Understanding of Neural Networks: The Power of
Initialization and a Dual View on Expressivity, NIPS16</li>
  <li>Domain Separation Networks, NIPS16</li>
  <li>The Robustness of Estimator Composition, NIPS16</li>
  <li>Composing graphical models with neural networks for structured
representations and fast inference, NIPS16</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/10/19/">
        Reliable Applications IV - Robustness to Data
      </a>
    </h1>

    <span class="post-date">- 19 Oct 2017</span>

    <ul>
  <li>Data Noising as Smoothing in Neural Network Language Models (Ng), ICLR17</li>
  <li>On Detecting Adversarial Perturbations, ICLR17</li>
  <li>Delving into Transferable Adversarial Examples and Black-box Attacks,
ICLR17</li>
  <li>Parseval Networks: Improving Robustness to Adversarial Examples, ICML17</li>
  <li>Being Robust (in High Dimensions) Can Be Practical, ICML17</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/10/17/">
        Reliable Applications III - Applications 2
      </a>
    </h1>

    <span class="post-date">- 17 Oct 2017</span>

    <ul>
  <li>Conditional Image Generation with Pixel CNN Decoders, NIPS16</li>
  <li>Learning to Query, Reason, and Answer Questions On Ambiguous Texts, ICLR17</li>
  <li>Visualizing Deep Neural Network Decisions: Prediction Difference
Analysis, ICLR17</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/10/12/">
        Reliable Applications II - Data
      </a>
    </h1>

    <span class="post-date">- 12 Oct 2017</span>

    <ul>
  <li>Measuring Sample Quality with Kernels,</li>
  <li>Semi-supervised Knowledge Transfer for Deep Learning from Private
Training Data, ICLR17</li>
  <li>Deep Learning with Differential Privacy,</li>
  <li>Privacy-Preserving Deep Learning, CCS15</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/10/10/">
        Reliable Applications I - Applications
      </a>
    </h1>

    <span class="post-date">- 10 Oct 2017</span>

    <ul>
  <li>Optimal Architectures in a Solvable Model of Deep Networks, NIPS16</li>
  <li>Input Switched Affine Networks: An RNN Architecture Designed for
Interpretability, Jakob Foerster, Justin Gilmer, Jan Chorowski, Jascha
Sohl-Dickstein, David Sussillo</li>
  <li>Axiomatic Attribution for Deep Networks, Ankur Taly, Qiqi Yan,Mukund
Sundararajan</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/10/05/">
        Structure VI - DNN with Adaptive Structures
      </a>
    </h1>

    <span class="post-date">- 05 Oct 2017</span>

    <ul>
  <li>AdaNet: Adaptive Structural Learning of Artificial Neural Networks, ICML17</li>
  <li>SplitNet: Learning to Semantically Split Deep Networks for Parameter
Reduction and Model Parallelization,</li>
  <li>Proximal Deep Structured Models, NIPS16</li>
  <li>Mollifying Networks, Bengio, ICLR17</li>
  <li>Towards Deep Interpretability (MUS-ROVER II): Learning Hierarchical
Representations of Tonal Music, ICLR17</li>
  <li>Input Switched Affine Networks: An RNN Architecture Designed for
Interpretability, ICML17</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/10/03/">
        Structure V - DNN with Memory
      </a>
    </h1>

    <span class="post-date">- 03 Oct 2017</span>

    <ul>
  <li>Ask Me Anything: Dynamic Memory Networks for Natural Language
Processing, ICML17</li>
  <li>Can Active Memory Replace Attention? Åukasz Kaiser*, ; Samy Bengio, NIPS16</li>
  <li>Reasoning with Memory Augmented Neural Networks for Language
Comprehension, ICLR17</li>
  <li>State-Frequency Memory Recurrent Neural Networks, ICML17</li>
  <li>Reasoning with Memory Augmented Neural Networks for Language
Comprehension, ICLR17</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/09/28/">
        Structure IV - DNN with Attention 2
      </a>
    </h1>

    <span class="post-date">- 28 Sep 2017</span>

    <ul>
  <li>Paying More Attention to Attention: Improving the Performance of
Convolutional Neural Networks via Attention Transfer, ICLR17</li>
  <li>Bidirectional Attention Flow for Machine Comprehension, ICLR17</li>
  <li>Dynamic Coattention Networks For Question Answering, ICLR17</li>
  <li>Structured Attention Networks, ICLR17</li>
  <li>Attend, Adapt and Transfer: Attentive Deep Architecture for Adaptive
Transfer from multiple sources in the same domain, ICLR17</li>
  <li>An Information-Theoretic Framework for Fast and Robust Unsupervised
Learning via Neural Population Infomax, ICLR17</li>
  <li>Image-to-Markup Generation with Coarse-to-Fine Attention, ICML17</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/09/26/">
        Structure III - DNN with Attention
      </a>
    </h1>

    <span class="post-date">- 26 Sep 2017</span>

    <ul>
  <li>Paying More Attention to Attention: Improving the Performance of
Convolutional Neural Networks via Attention Transfer, ICLR17</li>
  <li>Bidirectional Attention Flow for Machine Comprehension, ICLR17</li>
  <li>Dynamic Coattention Networks For Question Answering, ICLR17</li>
  <li>Structured Attention Networks, ICLR17</li>
  <li>Attend, Adapt and Transfer: Attentive Deep Architecture for Adaptive
Transfer from multiple sources in the same domain, ICLR17</li>
  <li>An Information-Theoretic Framework for Fast and Robust Unsupervised
Learning via Neural Population Infomax, ICLR17</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/09/21/">
        Structure II - DNN with Varying Structures
      </a>
    </h1>

    <span class="post-date">- 21 Sep 2017</span>

    <ul>
  <li>Outrageously Large Neural Networks: The Sparsely-Gated
Mixture-of-Experts Layer, (Dean), ICLR17</li>
  <li>Nonparametric Neural Networks, ICLR17</li>
  <li>
    <p>Sequence Modeling via Segmentations,</p>
  </li>
  <li>Towards Deep Interpretability (MUS-ROVER II): Learning Hierarchical
Representations of Tonal Music, ICLR17</li>
  <li>Input Switched Affine Networks: An RNN Architecture Designed for
Interpretability, ICML17</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/09/19/">
        Structure I - Varying DNN structures for an application
      </a>
    </h1>

    <span class="post-date">- 19 Sep 2017</span>

    <ul>
  <li>Making Neural Programming Architectures Generalize via Recursion, ICLR17</li>
  <li>Optimization as a Model for Few-Shot Learning, ICLR17</li>
  <li>Learning End-to-End Goal-Oriented Dialog, ICLR17</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/09/14/">
        Foundations VI - More about Behaviors of DNN
      </a>
    </h1>

    <span class="post-date">- 14 Sep 2017</span>

    <ul>
  <li>Large-Scale Evolution of Image Classifiers, Esteban Real, Sherry
Moore, Andrew Selle, Saurabh Saxena, Yutaka Leon Suematsu, Jie Tan, Quoc
V. Le, Alexey Kurakin ; PMLR 70:2902-2911</li>
  <li>A Closer Look at Memorization in Deep Networks, ICML17</li>
  <li>Dense Associative Memory for Pattern Recognition, NIPS16</li>
  <li>Learning Kernels with Random Features, Aman Sinha*, Stanford
University; John Duchi,</li>
  <li>Learning Structured Sparsity in Deep Neural Networks, NIPS16</li>
  <li>Learning the Number of Neurons in Deep Networks, NIPS16</li>
  <li>Learning Deep Parsimonious Representations, NIPS16</li>
  <li>Sharir - Overlapping Architectures.pdf
https://drive.google.com/file/d/0B6NHiPcsmak1ZzVkci1EdVN2YkU/view?usp=drive_web</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/09/12/">
        Foundations V - More about Behaviors of DNN
      </a>
    </h1>

    <span class="post-date">- 12 Sep 2017</span>

    <ul>
  <li>Large-Scale Evolution of Image Classifiers, Esteban Real, Sherry
Moore, Andrew Selle, Saurabh Saxena, Yutaka Leon Suematsu, Jie Tan, Quoc
V. Le, Alexey Kurakin ; PMLR 70:2902-2911</li>
  <li>A Closer Look at Memorization in Deep Networks, ICML17</li>
  <li>Dense Associative Memory for Pattern Recognition, NIPS16</li>
  <li>Learning Kernels with Random Features, Aman Sinha*, Stanford
University; John Duchi,</li>
  <li>Learning Structured Sparsity in Deep Neural Networks, NIPS16</li>
  <li>Learning the Number of Neurons in Deep Networks, NIPS16</li>
  <li>Learning Deep Parsimonious Representations, NIPS16</li>
  <li>Sharir - Overlapping Architectures.pdf
https://drive.google.com/file/d/0B6NHiPcsmak1ZzVkci1EdVN2YkU/view?usp=drive_web</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/09/07/">
        Foundations IV - Investigating Behaviors of DNN
      </a>
    </h1>

    <span class="post-date">- 07 Sep 2017</span>

    <ul>
  <li>Geometry of Neural Network Loss Surfaces via Random Matrix Theory,
Jeffrey Pennington, Yasaman Bahri</li>
  <li>On the Expressive Power of Deep Neural Networks, Maithra Raghu, Ben
Poole, Surya Ganguli, Jon Kleinberg, Jascha Sohl-Dickstein</li>
  <li>Understanding deep learning requires rethinking generalization, ICLR17</li>
  <li>On Large-Batch Training for Deep Learning: Generalization Gap and
Sharp Minima, ICLR17</li>
  <li>Why Deep Neural Networks for Function Approximation?, ICLR17</li>
  <li>Equivariance Through Parameter-Sharing, Siamak Ravanbakhsh, Jeff
Schneider, BarnabÃ¡s PÃ³czos ; PMLR 70:2892-2901</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/09/05/">
        Foundations III - Investigating Behaviors of DNN
      </a>
    </h1>

    <span class="post-date">- 05 Sep 2017</span>

    <ul>
  <li>Geometry of Neural Network Loss Surfaces via Random Matrix Theory,
Jeffrey Pennington, Yasaman Bahri</li>
  <li>On the Expressive Power of Deep Neural Networks, Maithra Raghu, Ben
Poole, Surya Ganguli, Jon Kleinberg, Jascha Sohl-Dickstein</li>
  <li>Understanding deep learning requires rethinking generalization, ICLR17</li>
  <li>On Large-Batch Training for Deep Learning: Generalization Gap and
Sharp Minima, ICLR17</li>
  <li>Why Deep Neural Networks for Function Approximation?, ICLR17</li>
  <li>Equivariance Through Parameter-Sharing, Siamak Ravanbakhsh, Jeff
Schneider, BarnabÃ¡s PÃ³czos ; PMLR 70:2892-2901</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/08/31/">
        Generative I - GAN tutorial by Ian Goodfellow
      </a>
    </h1>

    <span class="post-date">- 31 Aug 2017</span>

    <h3 id="gan-tutorial-by-ian-goodfellow-nips-2016">GAN tutorial by Ian Goodfellow (NIPS 2016):</h3>
<ul>
  <li>https://arxiv.org/abs/1701.00160</li>
  <li>https://www.youtube.com/watch?v=AJVyzd0rqdc</li>
</ul>

<h3 id="goodfellow---generative-models-i---dlss-2017">Goodfellow - Generative Models I - DLSS 2017</h3>
<ul>
  <li>https://drive.google.com/file/d/0ByUKRdiCDK7-bTgxTGoxYjQ4NW8/view</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/08/29/">
        Reinforcement I - Pineau - RL Basic Concepts
      </a>
    </h1>

    <span class="post-date">- 29 Aug 2017</span>

    <h3 id="pineau---rl-basic-concepts">Pineau - RL Basic Concepts</h3>
<ul>
  <li>https://drive.google.com/file/d/0BzUSSMdMszk6bjl3eU5CVmU0cWs/view</li>
  <li>http://videolectures.net/deeplearning2016_pineau_reinforcement_learning/</li>
  <li>http://videolectures.net/deeplearning2016_pineau_advanced_topics/</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/08/24/">
        Foundations II - Ganguli - Theoretical Neuroscience and Deep Learning DLSS16
      </a>
    </h1>

    <span class="post-date">- 24 Aug 2017</span>

    <h3 id="ganguli---theoretical-neuroscience-and-deep-learning-dlss16">Ganguli - Theoretical Neuroscience and Deep Learning DLSS16</h3>

<ul>
  <li>http://videolectures.net/deeplearning2016_ganguli_theoretical_neuroscience/</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/08/22/">
        Foundations I -Andrew Ng - Nuts and Bolts of Applying Deep Learning
      </a>
    </h1>

    <span class="post-date">- 22 Aug 2017</span>

    <h3 id="andrew-ng---nuts-and-bolts-of-applying-deep-learning">Andrew Ng - Nuts and Bolts of Applying Deep Learning:</h3>

<ul>
  <li>https://www.youtube.com/watch?v=F1ka6a13S9I</li>
</ul>

  </div>
  

</div>

</div>

    </div>

  </body>
</html>
